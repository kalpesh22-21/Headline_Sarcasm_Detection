{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tensorflow import saved_model\n",
    "import re\n",
    "import tensorflow\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.math import reduce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset\n",
    "data = pd.read_json('Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline\n",
       "0             1  thirtysomething scientists unveil doomsday clo...\n",
       "1             0  dem rep. totally nails why congress is falling...\n",
       "2             0  eat your veggies: 9 deliciously different recipes\n",
       "3             1  inclement weather prevents liar from getting t...\n",
       "4             1  mother comes pretty close to using word 'strea..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the article link column\n",
    "data.drop(['article_link'],inplace = True,axis =1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalpe\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='is_sarcastic', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class balance\n",
    "sns.countplot(data['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Sarcastic : 52.360320067088296 %\n",
      "Sarcastic : 47.6396799329117 %\n"
     ]
    }
   ],
   "source": [
    "print('Non Sarcastic : {0} %'.format((data['is_sarcastic'].value_counts()[0]/(data['is_sarcastic'].value_counts()[0] + data['is_sarcastic'].value_counts()[1] ))* 100))\n",
    "print('Sarcastic : {0} %'.format((data['is_sarcastic'].value_counts()[1]/(data['is_sarcastic'].value_counts()[0] + data['is_sarcastic'].value_counts()[1] ))* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_word_cloud(column):\n",
    "    \n",
    "    comment_words = ' '\n",
    "    stopwords = set(STOPWORDS)\n",
    "\n",
    "    # iterate through the csv file \n",
    "    for val in column: \n",
    "\n",
    "        # typecaste each val to string \n",
    "        val = str(val) \n",
    "\n",
    "        # split the value \n",
    "        tokens = val.split() \n",
    "\n",
    "        # Converts each token into lowercase \n",
    "        for i in range(len(tokens)):\n",
    "            tokens[i] = tokens[i].lower() \n",
    "\n",
    "        for words in tokens: \n",
    "            comment_words = comment_words + words + ' '\n",
    "\n",
    "\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    min_font_size = 10).generate(comment_words) \n",
    "    \n",
    "    return wordcloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non sarcastic class is more than sarcastic class. But there is acceptable class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat your veggies: 9 deliciously different recipes\n",
      "Length of the sentence is : 7\n",
      "Maximum Length of a headline in data set is : 151\n"
     ]
    }
   ],
   "source": [
    "# length of the sentence\n",
    "print(data['headline'][2])\n",
    "print('Length of the sentence is : {0}'.format(len(data['headline'][2].split(' '))))\n",
    "\n",
    "max_length = 0\n",
    "for i in range(data.shape[0]):\n",
    "    temp = len(data['headline'][i].split(' '))\n",
    "    if temp > max_length:\n",
    "        max_length = temp\n",
    "print('Maximum Length of a headline in data set is : {0}'.format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot wheels ranked number one toy for rolling down ramp, knocking over dominoes that send marble down a funnel, dropping onto teeter-totter that yanks on string, causing pulley system to raise wooden block, propelling series of twine rollers that unwind spring, launching tennis ball across room, inching tire down slope until it hits power switch, activating table fan that blows toy ship with nail attached to it across kiddie pool, popping water balloon that fills cup, weighing down lever that forces basketball down track, nudging broomstick on axis to rotate, allowing golf ball to roll into sideways coffee mug, which tumbles down row of hardcover books until handle catches hook attached to lever that causes wooden mallet to slam down on serving spoon, catapulting small ball into cup attached by ribbon to lazy susan, which spins until it pushes d battery down incline plane, tipping over salt shaker to season omelet\n"
     ]
    }
   ],
   "source": [
    "print(data['headline'][7302])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing all alpha_numeric characters\n",
    "# Temp = []\n",
    "# for i in range(data.shape[0]):\n",
    "#     Temp.append(re.sub(r'[^a-zA-Z_\\s]+','',data['headline'][i]))\n",
    "# data['cleaned_headline'] = Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9_\\s]+','',text)\n",
    "#     text = ' '.join([w for w in text.split() if w not in stopwords.words('english')])\n",
    "    return(text)\n",
    "data['cleaned_headline'] = data['headline'].apply(format_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: thirtysomething scientists unveil doomsday clock of hair loss\n",
      "After : thirtysomething scientists unveil doomsday clock of hair loss\n",
      "\t\n",
      "Before: dem rep. totally nails why congress is falling short on gender, racial equality\n",
      "After : dem rep totally nails why congress is falling short on gender racial equality\n",
      "\t\n",
      "Before: eat your veggies: 9 deliciously different recipes\n",
      "After : eat your veggies 9 deliciously different recipes\n",
      "\t\n",
      "Before: inclement weather prevents liar from getting to work\n",
      "After : inclement weather prevents liar from getting to work\n",
      "\t\n",
      "Before: mother comes pretty close to using word 'streaming' correctly\n",
      "After : mother comes pretty close to using word streaming correctly\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "# After removing alpha numeric characters\n",
    "for i in range(5):\n",
    "    print('Before: {0}'.format(data['headline'][i]))\n",
    "    print('After : {0}'.format(data['cleaned_headline'][i]))\n",
    "    print('\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_of_headline = 50\n",
    "num_words = 10000\n",
    "Embedding_dimension = 50\n",
    "lstm_out = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = data['cleaned_headline'].values\n",
    "\n",
    "# labels\n",
    "Y = data['is_sarcastic'].values\n",
    "Y = to_categorical(Y,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,stratify = Y,random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenizing and GLove Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "filename = 'tokenizer.pickle'\n",
    "pickle.dump(tokenizer, open(filename, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word_index_vector \n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vocabulary of the text is : 24809\n"
     ]
    }
   ],
   "source": [
    "Vocab_length = len(tokenizer.word_index)\n",
    "print('The Vocabulary of the text is : {0}'.format(Vocab_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading and reading GLove Embeddings\n",
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            curr_word = w_line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLove Embedding vector\n",
    "word_to_glove_map = read_glove_vector('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Embedding Matrix \n",
    "Emb_matrix = np.zeros((Vocab_length+1,Embedding_dimension))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_glove_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        Emb_matrix[index, :] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.68047 , -0.039263,  0.30186 , ..., -0.073297, -0.064699,\n",
       "        -0.26044 ],\n",
       "       [ 0.70853 ,  0.57088 , -0.4716  , ..., -0.22562 , -0.093918,\n",
       "        -0.80375 ],\n",
       "       ...,\n",
       "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.51888 , -0.35872 ,  0.24872 , ...,  0.59534 , -0.17319 ,\n",
       "        -0.24333 ],\n",
       "       [-0.40886 ,  0.64601 , -0.44272 , ...,  0.32651 , -0.18354 ,\n",
       "         0.031975]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emb_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train,maxlen=50,padding='post',value=0)\n",
    "x_test = pad_sequences(x_test,maxlen=50,padding='post',value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout,Bidirectional,Input\n",
    "\n",
    "Input = Input(shape = (50,))\n",
    "embeding = Embedding(Vocab_length+1, Embedding_dimension, input_length= max_length_of_headline,weights = [Emb_matrix], trainable=True)(Input)\n",
    "dropout = Dropout(0.2)(embeding)\n",
    "lstm = Bidirectional(LSTM(lstm_out, recurrent_dropout=0.2))(dropout)\n",
    "hidden_dense = Dense(10,activation ='relu')(lstm)\n",
    "output = Dense(2,activation='softmax')(hidden_dense)\n",
    "\n",
    "model = Model(inputs = Input,outputs =output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 50)            1240500   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100)               40400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 1,281,932\n",
      "Trainable params: 1,281,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "Optimizer = tensorflow.keras.optimizers.Adam(learning_rate = 1e-4,beta_1 = 0.99,decay = 1e-5)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=Optimizer,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Callbacks\n",
    "EarlyStopping = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=4,min_delta = 0.01)\n",
    "\n",
    "ModelCheckpoint = tensorflow.keras.callbacks.ModelCheckpoint(\"Proj_2_model-{val_loss:.2f}.h5\",monitor='loss',save_best_only= True,save_weights_only=True)\n",
    "\n",
    "reduceLoss = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01,patience=2, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "627/627 [==============================] - 32s 48ms/step - loss: 0.6662 - accuracy: 0.6047 - val_loss: 0.6234 - val_accuracy: 0.6783\n",
      "Epoch 2/20\n",
      "627/627 [==============================] - 30s 48ms/step - loss: 0.5759 - accuracy: 0.7074 - val_loss: 0.5252 - val_accuracy: 0.7449\n",
      "Epoch 3/20\n",
      "627/627 [==============================] - 33s 53ms/step - loss: 0.5077 - accuracy: 0.7498 - val_loss: 0.4742 - val_accuracy: 0.7764\n",
      "Epoch 4/20\n",
      "627/627 [==============================] - 31s 49ms/step - loss: 0.4616 - accuracy: 0.7814 - val_loss: 0.4368 - val_accuracy: 0.8010\n",
      "Epoch 5/20\n",
      "627/627 [==============================] - 29s 46ms/step - loss: 0.4297 - accuracy: 0.8024 - val_loss: 0.4117 - val_accuracy: 0.8178\n",
      "Epoch 6/20\n",
      "627/627 [==============================] - 28s 45ms/step - loss: 0.4121 - accuracy: 0.8133 - val_loss: 0.3936 - val_accuracy: 0.8261\n",
      "Epoch 7/20\n",
      "627/627 [==============================] - 29s 46ms/step - loss: 0.3857 - accuracy: 0.8262 - val_loss: 0.3789 - val_accuracy: 0.8348\n",
      "Epoch 8/20\n",
      "627/627 [==============================] - 28s 45ms/step - loss: 0.3679 - accuracy: 0.8360 - val_loss: 0.3705 - val_accuracy: 0.8385\n",
      "Epoch 9/20\n",
      "627/627 [==============================] - 31s 50ms/step - loss: 0.3547 - accuracy: 0.8438 - val_loss: 0.3589 - val_accuracy: 0.8447\n",
      "Epoch 10/20\n",
      "627/627 [==============================] - 33s 53ms/step - loss: 0.3420 - accuracy: 0.8510 - val_loss: 0.3505 - val_accuracy: 0.8482\n",
      "Epoch 11/20\n",
      "627/627 [==============================] - 36s 58ms/step - loss: 0.3274 - accuracy: 0.8582 - val_loss: 0.3463 - val_accuracy: 0.8492\n",
      "Epoch 12/20\n",
      "627/627 [==============================] - 34s 54ms/step - loss: 0.3203 - accuracy: 0.8613 - val_loss: 0.3384 - val_accuracy: 0.8530\n",
      "Epoch 13/20\n",
      "627/627 [==============================] - 33s 53ms/step - loss: 0.3087 - accuracy: 0.8667 - val_loss: 0.3417 - val_accuracy: 0.8523\n",
      "Epoch 14/20\n",
      "627/627 [==============================] - 30s 47ms/step - loss: 0.2987 - accuracy: 0.8708 - val_loss: 0.3346 - val_accuracy: 0.8569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1562300fa00>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 20 , batch_size= 32,  validation_data=(x_test,y_test),callbacks = [EarlyStopping,reduceLoss,ModelCheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the best model\n",
    "Final_model = Model(inputs = Input,outputs =output)\n",
    "Final_model.load_weights('Proj_2_model-0.33.h5')\n",
    "Final_model.compile(loss = 'categorical_crossentropy', optimizer=Optimizer,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 - 2s - loss: 0.3279 - accuracy: 0.8576\n",
      "Loss on Test Data : 0.33\n",
      "Accuracy on test Data : 0.86\n"
     ]
    }
   ],
   "source": [
    "# Accuracy and Loss\n",
    "score,acc = Final_model.evaluate(x_test, y_test, verbose = 2, batch_size = 32)\n",
    "\n",
    "print(\"Loss on Test Data : %.2f\" % (score))\n",
    "print(\"Accuracy on test Data : %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : \"undecided debate viewer waiting until he hears same responses for seventh time before making decision\"\"\n",
      "Model Prediction : The headline is Sarcastic\n",
      "Truth Value      : The headline is Sarcastic\n",
      "Correct Prediction !!!\n"
     ]
    }
   ],
   "source": [
    "i = 11016\n",
    "# Test sentence\n",
    "Test_sentence = data['cleaned_headline'][i]\n",
    "print('Sentence : \"{0}\"\"'.format(Test_sentence))\n",
    "\n",
    "# converting the sentence to sequence\n",
    "Test = tokenizer.texts_to_sequences([Test_sentence])\n",
    "Test = pad_sequences(Test,maxlen=50,padding='post',value =0)\n",
    "\n",
    "# Predicting\n",
    "result = Final_model.predict(Test)[0]\n",
    "\n",
    "if np.argmax(result) == 1:\n",
    "    print(\"Model Prediction : The headline is Sarcastic\")\n",
    "else:\n",
    "    print('Model Prediction : The headline is not Sarcastic')\n",
    "\n",
    "if data['is_sarcastic'][i] == 1:\n",
    "    print(\"Truth Value      : The headline is Sarcastic\")\n",
    "else:\n",
    "    print('Truth Value      : The headline is not Sarcastic')\n",
    "    \n",
    "if np.argmax(result) == data['is_sarcastic'][i]:\n",
    "    print('Correct Prediction !!!')\n",
    "else:\n",
    "    print('Wrong Prediction !!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1451935e-04, 9.9938548e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_model.predict(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "save_model(model,'model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
